{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f623a387-c3c4-4897-b0ae-20d524cbfebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from SeqEN2.session import Session\n",
    "from SeqEN2.model.model import Model\n",
    "from SeqEN2.autoencoder.autoencoder import Autoencoder\n",
    "from glob import glob\n",
    "from os import system\n",
    "from torch import no_grad\n",
    "from torch import argmax, tensor, index_select, mode, diagonal, fliplr, eye\n",
    "from torch import sum as torch_sum\n",
    "import torch\n",
    "import numpy as np\n",
    "import cProfile\n",
    "import pstats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "57fbf0e8-53da-4f28-afe7-797bf75c2b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def consensus(output, ndx, device):\n",
    "    output_length, w = output.shape\n",
    "    seq_length = output_length + w - 1\n",
    "    filter_size = min(seq_length - ndx, ndx + 1)\n",
    "    if filter_size > w:\n",
    "        filter_size = w\n",
    "    r_min = max(0, ndx - w + 1)\n",
    "    r_max = r_min + filter_size\n",
    "    r_indices = tensor(range(r_min, r_max), device=device)\n",
    "    c_min = max(0, ndx - output_length + 1)\n",
    "    c_max = min(ndx, w - 1) + 1\n",
    "    c_indices = tensor(range(c_min, c_max), device=device)\n",
    "    sub_result = index_select(index_select(output, 0, r_indices), 1, c_indices)\n",
    "    val = mode(diagonal(fliplr(fliplr(eye(filter_size, device=device).long()) * sub_result)))\n",
    "    return val.values.item()\n",
    "\n",
    "\n",
    "def get_seq(ndx, ndx_windows):\n",
    "    output_length, w = ndx_windows.shape\n",
    "    seq_length = output_length + w - 1\n",
    "    if ndx < output_length:\n",
    "        return ndx_windows[ndx][0]\n",
    "    elif ndx < seq_length:\n",
    "        return ndx_windows[-1][ndx-output_length+1]\n",
    "    else:\n",
    "        raise IndexError(f'index {ndx-output_length+1} is out of bounds for dimension 1 with size {w}')\n",
    "\n",
    "\n",
    "def consensus_acc(seq, output, device):\n",
    "    output_length, w = output.shape\n",
    "    seq_length = output_length + w - 1\n",
    "    n = 0\n",
    "    consensus_seq = []\n",
    "    for i in range(seq_length):\n",
    "        consensus_seq.append(consensus(output, i, device=device))\n",
    "        if get_seq(i, seq).item() == consensus_seq[-1]:\n",
    "            n += 1\n",
    "    return n / len(seq), consensus_seq\n",
    "\n",
    "def main(w, l):\n",
    "    ol = l - w + 1\n",
    "    output = torch.randint(0, 21, (ol, w)).long()\n",
    "    seq = torch.randint(0, 21, (l,)).long()\n",
    "    consensus_acc = consensus_acc(seq, output, 'cpu') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "af32a48d-1640-4d63-a2ab-50502f372a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# l = 100\n",
    "# w = 20\n",
    "# ol = l - w + 1\n",
    "# output = torch.randint(0, 21, (ol, w)).long()\n",
    "# get_seq(20, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1ca5834b-f1c9-45d5-8919-0794225fb8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# l = 100\n",
    "# w = 20\n",
    "# r = 100\n",
    "# job = f'tensor_{w}_{l}_{r}'\n",
    "# job = f'np_{w}_{l}_{r}'\n",
    "\n",
    "# with cProfile.Profile() as pr:\n",
    "#     for _ in range(r):\n",
    "#         main(w, l)\n",
    "# stats = pstats.Stats(pr)\n",
    "# stats.sort_stats(pstats.SortKey.TIME)\n",
    "# stats.print_stats()\n",
    "# filename=f'./profiling_{job}.prof'\n",
    "# stats.dump_stats(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f051199f-33d3-4114-b642-0b84e985e6e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b4c6439e-b6b7-45c9-a175-fe1bfce4d986",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewAutoencoder(Autoencoder):\n",
    "    def test_batch(self, input_vals, device, input_noise=0.0, wandb_log=True):\n",
    "        \"\"\"\n",
    "        Test a single batch of data, this will move into autoencoder\n",
    "        :param input_vals:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        with no_grad():\n",
    "            input_ndx, one_hot_input = self.transform_input(input_vals, device, input_noise=input_noise)\n",
    "            reconstructor_output = self.forward_test(one_hot_input)\n",
    "            reconstructor_loss = self.criterion_NLLLoss(reconstructor_output, input_ndx.reshape((-1,)))\n",
    "            # reconstructor acc\n",
    "            reconstructor_ndx = argmax(reconstructor_output, dim=1)\n",
    "            reconstructor_accuracy = (\n",
    "                torch_sum(reconstructor_ndx == input_ndx.reshape((-1,))) / reconstructor_ndx.shape[0]\n",
    "            )\n",
    "            consensus_seq_acc, consensus_seq = consensus_acc(input_ndx, reconstructor_ndx.reshape((-1, self.w)), device)\n",
    "            # reconstruction_loss, discriminator_loss, classifier_loss\n",
    "            if wandb_log:\n",
    "                wandb.log({\"test_reconstructor_loss\": reconstructor_loss.item()})\n",
    "                wandb.log({\"test_reconstructor_accuracy\": reconstructor_accuracy.item()})\n",
    "                wandb.log({\"test_consensus_accuracy\": consensus_seq_acc})\n",
    "            else:\n",
    "                return (\n",
    "                    reconstructor_loss,\n",
    "                    reconstructor_accuracy,\n",
    "                    consensus_seq_acc,\n",
    "                    consensus_seq,\n",
    "                )\n",
    "            # clean up\n",
    "            del reconstructor_loss\n",
    "            del reconstructor_output\n",
    "            return\n",
    "\n",
    "class NewModel(Model):\n",
    "    def build_model(self, model_type, arch):\n",
    "        if model_type == \"AE\":\n",
    "            self.autoencoder = NewAutoencoder(self.d0, self.d1, self.dn, self.w, arch)\n",
    "        # elif model_type == \"AAE\":\n",
    "        #     self.autoencoder = AdversarialAutoencoder(\n",
    "        #         self.d0, self.d1, self.dn, self.w, arch\n",
    "        #     )\n",
    "        # elif model_type == \"AAEC\":\n",
    "        #     self.autoencoder = AdversarialAutoencoderClassifier(\n",
    "        #         self.d0, self.d1, self.dn, self.w, arch\n",
    "        #     )\n",
    "        self.autoencoder.to(self.device)\n",
    "    \n",
    "    def predict(self, num_test_items=1, input_noise=0.0):\n",
    "        \"\"\"\n",
    "        The main training loop for a model\n",
    "        :param num_test_items:\n",
    "        :param input_noise:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        for test_batch in self.data_loader.get_test_batch(num_test_items=num_test_items):\n",
    "            results = self.autoencoder.test_batch(test_batch, self.device, input_noise=input_noise, wandb_log=False)\n",
    "            # do stuff with results\n",
    "\n",
    "class NewSession(Session):\n",
    "    \n",
    "    def add_model(self, name, arch, model_type, d0=21, d1=8, dn=10, w=20):\n",
    "        arch = self.load_arch(arch)\n",
    "        if self.model is None:\n",
    "            self.model = NewModel(name, arch, model_type, d0=d0, d1=d1, dn=dn, w=w)\n",
    "            \n",
    "    def load_data(self, dataset_name):\n",
    "        data_files = sorted(glob(str(Model.root) + f\"/data/{dataset_name}/*.csv.gz\"))[:2]\n",
    "        self.model.load_data(dataset_name, data_files)\n",
    "        \n",
    "    def test(self, num_test_items=1, input_noise=0.0):\n",
    "        self.model.test(num_test_items=num_test_items, input_noise=input_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f67c89b8-f8bd-43a3-bfe5-2374803dbc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = NewSession()\n",
    "model_name = 'dummy'\n",
    "arch = 'gen1'\n",
    "model_type = 'AE'\n",
    "dataset = 'w_20_KeggSeq_ndx_wpACT'\n",
    "run_title = 'prototyping_consensus_acc'\n",
    "w = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1fd87b42-3ba7-4820-b128-df07ee1ea851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test batch shape:  (353, 22)\n",
      "input vals shape : (353, 22)\n",
      "input ndx shape : torch.Size([353, 20])\n",
      "input onehot shape : torch.Size([353, 20, 21])\n",
      "output shape : torch.Size([353, 20])\n"
     ]
    }
   ],
   "source": [
    "session.add_model(model_name, arch, model_type)\n",
    "session.load_data(dataset)\n",
    "result = session.test(num_test_items=1, input_noise=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9a8d90ba-ca61-4eee-ac58-9749592d0fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac03d6cf-9fa9-4b41-913f-d07d22dabc4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e7e005-2b8d-467e-9976-29ce6305cafa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "2381727b-ea5a-4c18-8901-4b8ce19d7bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56b986d-c647-4665-aa38-9b76820a85ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81475d64-1bf7-4857-a9e8-684501a05f37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb567708-7f70-46bb-87cb-6ed8a2b7432c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26d9550-75bd-40e2-801d-271976431188",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3fdb0e-2e3a-4b24-85ab-6b64f49c2a13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e705b3-975d-4c69-8c89-b4a56f3cfdcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e3564a-e988-486e-802e-e1e6659987ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b999543e-8b61-45ff-b0df-12d74fbdb629",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91e91d2-5cc5-4aad-a180-2e8462a2e759",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061c6556-54ee-4647-9cd1-bc7a1f0ab5c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c88204-b414-4336-b3ee-09000fcc2215",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e0b76a-d8e2-423c-ae77-e215d50c46bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70679e8a-d7dc-45d5-bd93-331b615722b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7595c33-6a9f-4956-825c-4e5798206e43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dfc771-8ab2-4bdf-9904-73fb1a21a5d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e059a05-99a5-445d-9889-7b273183a55c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e72cddc-802e-4f43-b071-cee07c609a4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde2267a-ce40-4b61-8032-7a6df5b33596",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
